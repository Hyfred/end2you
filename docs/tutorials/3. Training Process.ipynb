{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training Process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "from pathlib import Path\n",
    "from end2you.training_process import TrainingProcess\n",
    "from end2you.utils import Params"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We use the class `Params` to elegantly define the parameters required for the training process.\n",
    "The parameters for the training process are the following:\n",
    "```\n",
    "- train: The parameters for the training process.\n",
    "    - batch_size        : The batch size to load.\n",
    "    - is_training       : If the loader is used in training or evaluation (always True here).\n",
    "    - cuda              : Load data in cuda.\n",
    "    - num_workers       : Number of workers to use to load data.\n",
    "    - seq_length        : Number of consecutive frames to load per batch.\n",
    "    - modality          : Modality to be used for. Values [`audio`, `visual`, `audiovisual`].\n",
    "    - dataset_path      : Path to training .hdf5 files.\n",
    "    - summarywriter_file: Name of the summarywriter file.\n",
    "    - num_epochs        : Number of epochs to perform training.\n",
    "    - save_summary_steps: Every which step to perform evaluation in training.\n",
    "    - loss              : Loss function to use. One of [`mse`, `ccc`, `ce`].\n",
    "    - learning_rate     : The learning rate to use for training.\n",
    "    - optimizer         : Optimizer to use. One defined in PyTorch (default `adam`).\n",
    "\n",
    "- valid: The parameters for the validation process.\n",
    "    - summarywriter_file: Name of the summarywriter file.\n",
    "    - dataset_path      : Path to validation .hdf5 files.\n",
    "    - metric            : Metric to use for evaluation. One of [`ccc`, `uar`, `mse`].\n",
    "    - cuda              : Load data in cuda (should be same as in train).\n",
    "    - num_workers       : Number of workers to use to load data.\n",
    "    - modality          : Modality to be used for. Values `audio`, `visual`, `audiovisual`.\n",
    "    - is_training       : If the loader is used in training or evaluation (always False here).\n",
    "    - batch_size        : Always 1.\n",
    "    - save_summary_steps: Always 1.\n",
    "    - seq_length        : Number of consecutive frames to load per batch.\n",
    "\n",
    "- model: The parameters of the model.\n",
    "    - num_outs: The number of outputs of the model.\n",
    "\n",
    "- root_dir: Path to save the output files of end2you.\n",
    "\n",
    "- log_file: Path to save log file\n",
    "\n",
    "- ckpt_path: Path to checkpoint. If not defined training starts from scratch.\n",
    "\n",
    "- num_gpus: Number of GPUs to use. Need to have more than one defined with `CUDA_VISIBLE_DEVICES`.\n",
    "```\n",
    "\n",
    "Example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = Params(dict_params={\n",
    "    'train':Params(dict_params={'loss':'ccc',\n",
    "                                'dataset_path':'/path/to/train/hdf5/files',\n",
    "                                'optimizer':'adam',\n",
    "                                'learning_rate':0.0002,\n",
    "                                'summarywriter_file':'train_sw',\n",
    "                                'num_epochs':50,\n",
    "                                'num_workers':2,\n",
    "                                'cuda':True, \n",
    "                                'modality':'audio',\n",
    "                                'batch_size':3,\n",
    "                                'is_training':True, # Always True\n",
    "                                'save_summary_steps':10, \n",
    "                                'seq_length': 150\n",
    "                               }),\n",
    "    'valid':Params(dict_params={'summarywriter_file':'eval_sw',\n",
    "                                'metric':'ccc',\n",
    "                                'dataset_path':'/path/to/valid/hdf5/files',\n",
    "                                'num_workers':2,\n",
    "                                'cuda':True,  \n",
    "                                'modality':'audio',\n",
    "                                'batch_size':1, # Always 1\n",
    "                                'save_summary_steps':1, # Always 1\n",
    "                                'is_training':False, # Always False\n",
    "                                'seq_length': 150\n",
    "                              }),\n",
    "    'model':Params(dict_params={'model_name':'audio', 'num_outs':3}),\n",
    "    'root_dir':'./path/to/save/output/files/of/end2you',\n",
    "    'log_file':'training.log',\n",
    "    'ckpt_path': None,\n",
    "    'num_gpus':1\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Defining the parameters we can now invoke the TrainingProcess class and start the training.\n",
    "For example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training = TrainingProcess(params)\n",
    "training.start()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "pytorch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
