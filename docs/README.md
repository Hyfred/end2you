## Tutorials

We provide tutorials to get you started with End2You. In particular we provide the following:

1. [Data Generation](https://github.com/end2you/end2you/blob/end2you_pytorch/docs/tutorials/1.%20Data%20Generation.ipynb)<br>
2. [Data Provider](https://github.com/end2you/end2you/blob/end2you_pytorch/docs/tutorials/2.%20Data%20Provider.ipynb)<br>
3. [Training Process](https://github.com/end2you/end2you/blob/end2you_pytorch/docs/tutorials/3.%20Training%20Process.ipynb)<br>
4. [Evaluation Process](https://github.com/end2you/end2you/blob/end2you_pytorch/docs/tutorials/4.%20Evaluation%20Process.ipynb)


## Models

### Audio

We provide two models that can handle the audio modality. Both of them are papers published in ICASSP.
The first one was published in 2018 and its architecture is shown below:

> `Tzirakis, P., Zhang, J., & Schuller, B. W. (2018, April). End-to-end speech emotion recognition using deep neural networks. In 2018 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP) (pp. 5089-5093). IEEE.`

![alt text](https://github.com/end2you/end2you/blob/end2you_pytorch/docs/figures/emo18.png "Speech Emotion Recognition - Emo18 model")

The second one was published in 2018 and its architecture is shown below:

> `Trigeorgis, George, Fabien Ringeval, Raymond Brueckner, Erik Marchi, Mihalis A. Nicolaou, Bj√∂rn Schuller, and Stefanos Zafeiriou. "Adieu features? end-to-end speech emotion recognition using a deep convolutional recurrent network." In 2016 IEEE international conference on acoustics, speech and signal processing (ICASSP), pp. 5200-5204. IEEE, 2016.`

![alt text](https://github.com/end2you/end2you/blob/end2you_pytorch/docs/figures/emo16.png "Speech Emotion Recognition - Emo16 model")


### Visual
